{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading input data and building the SFS\n",
    "\n",
    "Now that our models are set up, we are ready to read out input data and convert it into site frequency spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delimitpy import parse_input\n",
    "from delimitpy import process_empirical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse configuration files and read in intermediate files from previous part of tutorial.\n",
    "\n",
    "We need to read our config file into memory again, and we need to read the files that were created in the 'Building a Model Set' notebook.\n",
    "\n",
    "The test data we are using was simulated under a model with three populations and no gene flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the configuraiton file\n",
    "config_parser = parse_input.ModelConfigParser(\"../../examples/test1/config.txt\")\n",
    "config_values = config_parser.parse_config()\n",
    "\n",
    "# read the labels and parameterized files\n",
    "labels = np.load(os.path.join(config_values[\"output directory\"], 'labels.npy'), allow_pickle=True)\n",
    "with open(os.path.join(config_values[\"output directory\"], 'parameterized_models.pickle'), 'rb') as f:\n",
    "    parameterized_models = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read empirical data, and convert it into a numpy array.\n",
    "\n",
    "First, generate our data processor. Then, we convert our folder of fasta files into a numpy array. We will keep the same number of sites that we kept for simulated data. Missing data will be encoded as -1 (any sites in the alignment other than A, T, C, and G will be converted to -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1038)\n"
     ]
    }
   ],
   "source": [
    "# create our data processor, and convert our fastas to a numpy array\n",
    "data_processor = process_empirical.DataProcessor(parameterized_models, config=config_values)\n",
    "empirical_array = data_processor.fasta_to_numpy()\n",
    "print(empirical_array.shape) # print the shape of our array: (individuals, SNPs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose projection for site-frequency-spectrum\n",
    "\n",
    "SFS cannot be generated from datasets that include missing data. To circumvent this, we use a downsampling approach such as that described in Satler and Carstens (2017, Molecular Ecology, doi: 10.1111/mec.14137.) We must choose thresholds for each populations (i.e., the minumum number of individuals that must be sampled for a SNP to be used.) To help with this, we use the function find_downsampling from the class DataProcessor. This function generates a dictionary that holds the number of SNPs that meet each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dictionary with the number of SNPs at different sampling thresholds\n",
    "empirical_2d_sfs_sampling = data_processor.find_downsampling(empirical_array)\n",
    "\n",
    "minspns = 1000\n",
    "min1000 ={key: value for key, value in empirical_2d_sfs_sampling.items() if value >= minspns}\n",
    "print(min10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build sfs\n"
     ]
    }
   ],
   "source": [
    "empirical_2d_sfs = data_processor.numpy_to_2d_sfs(empirical_array, downsampling={\"A\":6, \"B\":4, \"C\":5}, replicates = 10)\n",
    "empirical_msfs = data_processor.numpy_to_msfs(empirical_array, downsampling={\"A\":6, \"B\": 4, \"C\":5}, replicates = 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
